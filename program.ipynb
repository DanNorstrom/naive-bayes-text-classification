{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "e8293e6e10a54ddd8cddc9b5f007ef34192abaa3c6406753b0cc265dd57a9253"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.metrics.scores import (precision, recall)\n",
    "import collections\n",
    "import string\n",
    "import random\n",
    "\n",
    "# sources\n",
    "# (textbook): https://www.nltk.org/book/ch06.html\n",
    "# https://stackabuse.com/text-classification-with-python-and-scikit-learn/\n",
    "# https://www.g2.com/products/nltk/competitors/alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[',', 'the', '.', 'a', 'and', 'of', 'to', \"'\", 'is', 'in']\n['film', 'one', 'movie', 'like', 'even', 'good', 'time', 'story', 'would', 'much']\n"
     ]
    }
   ],
   "source": [
    "## pre-processing ##\n",
    "# removes punctuation and all common stopwords in english\n",
    "stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "noPunct_all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words() if w not in stop)\n",
    "\n",
    "\n",
    "## eye-level-control comparrison of pre-processing outcome ##\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "old_words = list(all_words)[:10]\n",
    "words = list(noPunct_all_words)[:10]\n",
    "print(old_words)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 3. Feature selection ##\n",
    "\n",
    "# Document array\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "\n",
    "# currently the 3000 most important words, the last words have higher occurance than the first words, comparing to the end for more matches, hence more relevant data.\n",
    "word_features = list(noPunct_all_words)[:3000]\n",
    "\n",
    "def get_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in document_words)\n",
    "    return features\n",
    "\n",
    "## example useage\n",
    "# print((get_features(movie_reviews.words('neg/cv000_29416.txt'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Classifier ##\n",
    "\n",
    "featuresets = [(get_features(d), c) for (d,c) in documents]\n",
    "\n",
    "# \"you should evaluate your model on 10% of movereview model, 10% 2000 = 200\"\n",
    "# evaluation-set\n",
    "test_set = featuresets[:200]\n",
    "\n",
    "# training-set, every set we can get excluding the test_set\n",
    "train_set = featuresets[1800:]\n",
    "\n",
    "## CHANGE CLASSIFER HERE ##\n",
    "# naive bayes classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Decision tree classifier\n",
    "#classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "#print(classifier.pseudocode(depth=4)) # shows the beginning of the tree (might be slow)\n",
    "\n",
    "# MaxentClassifier (dosen't give neg statistics)\n",
    "# classifier = nltk.MaxentClassifier.train(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Document 1: is neg\n",
      "Document 2: is neg\n",
      "Document 3: is neg\n",
      "Document 4: is pos\n",
      "Document 5: is neg\n",
      "Document 6: is pos\n",
      "Document 7: is neg\n",
      "Document 8: is neg\n",
      "Document 9: is pos\n",
      "Document 10: is pos\n",
      "Document 11: is pos\n",
      "Document 12: is pos\n",
      "Document 13: is neg\n",
      "Document 14: is neg\n",
      "Document 15: is pos\n",
      "Document 16: is neg\n",
      "Document 17: is neg\n",
      "Document 18: is pos\n",
      "Document 19: is neg\n",
      "Document 20: is neg\n",
      "Document 21: is pos\n",
      "Document 22: is pos\n",
      "Document 23: is pos\n",
      "Document 24: is pos\n",
      "Document 25: is pos\n",
      "Document 26: is pos\n",
      "Document 27: is neg\n",
      "Document 28: is neg\n",
      "Document 29: is pos\n",
      "Document 30: is pos\n",
      "Document 31: is neg\n",
      "Document 32: is neg\n",
      "Document 33: is neg\n",
      "Document 34: is neg\n",
      "Document 35: is neg\n",
      "Document 36: is pos\n",
      "Document 37: is neg\n",
      "Document 38: is neg\n",
      "Document 39: is neg\n",
      "Document 40: is pos\n",
      "Document 41: is pos\n",
      "Document 42: is neg\n",
      "Document 43: is pos\n",
      "Document 44: is neg\n",
      "Document 45: is neg\n",
      "Document 46: is pos\n",
      "Document 47: is neg\n",
      "Document 48: is neg\n",
      "Document 49: is pos\n",
      "Document 50: is pos\n",
      "Document 51: is neg\n",
      "Document 52: is pos\n",
      "Document 53: is pos\n",
      "Document 54: is neg\n",
      "Document 55: is neg\n",
      "Document 56: is pos\n",
      "Document 57: is pos\n",
      "Document 58: is neg\n",
      "Document 59: is neg\n",
      "Document 60: is neg\n",
      "Document 61: is pos\n",
      "Document 62: is neg\n",
      "Document 63: is pos\n",
      "Document 64: is pos\n",
      "Document 65: is neg\n",
      "Document 66: is pos\n",
      "Document 67: is pos\n",
      "Document 68: is pos\n",
      "Document 69: is pos\n",
      "Document 70: is neg\n",
      "Document 71: is pos\n",
      "Document 72: is neg\n",
      "Document 73: is neg\n",
      "Document 74: is neg\n",
      "Document 75: is pos\n",
      "Document 76: is neg\n",
      "Document 77: is pos\n",
      "Document 78: is pos\n",
      "Document 79: is neg\n",
      "Document 80: is pos\n",
      "Document 81: is neg\n",
      "Document 82: is neg\n",
      "Document 83: is pos\n",
      "Document 84: is neg\n",
      "Document 85: is neg\n",
      "Document 86: is pos\n",
      "Document 87: is pos\n",
      "Document 88: is neg\n",
      "Document 89: is pos\n",
      "Document 90: is neg\n",
      "Document 91: is pos\n",
      "Document 92: is neg\n",
      "Document 93: is pos\n",
      "Document 94: is neg\n",
      "Document 95: is neg\n",
      "Document 96: is neg\n",
      "Document 97: is neg\n",
      "Document 98: is neg\n",
      "Document 99: is neg\n",
      "Document 100: is pos\n",
      "Document 101: is neg\n",
      "Document 102: is pos\n",
      "Document 103: is neg\n",
      "Document 104: is neg\n",
      "Document 105: is pos\n",
      "Document 106: is neg\n",
      "Document 107: is neg\n",
      "Document 108: is pos\n",
      "Document 109: is pos\n",
      "Document 110: is neg\n",
      "Document 111: is neg\n",
      "Document 112: is neg\n",
      "Document 113: is pos\n",
      "Document 114: is pos\n",
      "Document 115: is pos\n",
      "Document 116: is neg\n",
      "Document 117: is pos\n",
      "Document 118: is neg\n",
      "Document 119: is pos\n",
      "Document 120: is pos\n",
      "Document 121: is pos\n",
      "Document 122: is pos\n",
      "Document 123: is pos\n",
      "Document 124: is pos\n",
      "Document 125: is neg\n",
      "Document 126: is neg\n",
      "Document 127: is pos\n",
      "Document 128: is neg\n",
      "Document 129: is neg\n",
      "Document 130: is pos\n",
      "Document 131: is pos\n",
      "Document 132: is pos\n",
      "Document 133: is pos\n",
      "Document 134: is neg\n",
      "Document 135: is pos\n",
      "Document 136: is pos\n",
      "Document 137: is pos\n",
      "Document 138: is pos\n",
      "Document 139: is neg\n",
      "Document 140: is pos\n",
      "Document 141: is neg\n",
      "Document 142: is neg\n",
      "Document 143: is neg\n",
      "Document 144: is neg\n",
      "Document 145: is neg\n",
      "Document 146: is pos\n",
      "Document 147: is neg\n",
      "Document 148: is pos\n",
      "Document 149: is neg\n",
      "Document 150: is neg\n",
      "Document 151: is pos\n",
      "Document 152: is pos\n",
      "Document 153: is neg\n",
      "Document 154: is neg\n",
      "Document 155: is neg\n",
      "Document 156: is pos\n",
      "Document 157: is pos\n",
      "Document 158: is neg\n",
      "Document 159: is neg\n",
      "Document 160: is neg\n",
      "Document 161: is neg\n",
      "Document 162: is pos\n",
      "Document 163: is pos\n",
      "Document 164: is pos\n",
      "Document 165: is pos\n",
      "Document 166: is neg\n",
      "Document 167: is neg\n",
      "Document 168: is pos\n",
      "Document 169: is pos\n",
      "Document 170: is neg\n",
      "Document 171: is pos\n",
      "Document 172: is neg\n",
      "Document 173: is pos\n",
      "Document 174: is neg\n",
      "Document 175: is neg\n",
      "Document 176: is pos\n",
      "Document 177: is neg\n",
      "Document 178: is neg\n",
      "Document 179: is pos\n",
      "Document 180: is neg\n",
      "Document 181: is neg\n",
      "Document 182: is neg\n",
      "Document 183: is neg\n",
      "Document 184: is neg\n",
      "Document 185: is pos\n",
      "Document 186: is neg\n",
      "Document 187: is neg\n",
      "Document 188: is neg\n",
      "Document 189: is neg\n",
      "Document 190: is pos\n",
      "Document 191: is pos\n",
      "Document 192: is neg\n",
      "Document 193: is neg\n",
      "Document 194: is pos\n",
      "Document 195: is neg\n",
      "Document 196: is pos\n",
      "Document 197: is pos\n",
      "Document 198: is neg\n",
      "Document 199: is neg\n",
      "Document 200: is pos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## data-struct for precision and recall ##\n",
    "\n",
    "# known labels \"golden labels\" - correct labels from corpus\n",
    "refsets = collections.defaultdict(set)\n",
    "\n",
    "# classifier output using test_set - aiming to get the same labels as refset\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "# build data-structs & report document pos/neg\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats) \n",
    "    testsets[observed].add(i)\n",
    "    print(f\"Document {i+1}: is {observed}\")\n",
    "\n",
    "\n",
    "# use classifier on a single document like so:\n",
    "# result = classifier.classify(some_document)"
   ]
  },
  {
   "source": [
    "<h1>Example Doc output:</h1><br>\n",
    "...<br>\n",
    "Document 36: is pos<br>\n",
    "Document 37: is neg<br>\n",
    "Document 38: is pos<br>\n",
    "Document 39: is neg<br>\n",
    "Document 40: is pos<br>\n",
    "Document 41: is neg<br>\n",
    "Document 42: is neg<br>\n",
    "Document 43: is pos<br>\n",
    "Document 44: is pos<br>\n",
    "...<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Positive class statistics: \n",
      "Precision: 79.57%\n",
      "Recall: 77.08%\n",
      "Accuracy: 79.50%\n",
      "F-score: 78.31%\n"
     ]
    }
   ],
   "source": [
    "## Report positive class ##\n",
    "print(f\"Positive class statistics: \")\n",
    "\n",
    "# report precision\n",
    "pSum = precision(refsets['pos'], testsets['pos'])\n",
    "print( f\"Precision: {pSum*100:.2f}%\")\n",
    "\n",
    "# report recall\n",
    "rSum = recall(refsets['pos'], testsets['pos'])\n",
    "print( f\"Recall: {rSum*100:.2f}%\")\n",
    "\n",
    "# report accuracy\n",
    "print(f\"Accuracy: {nltk.classify.accuracy(classifier, test_set)*100:.2f}%\")\n",
    "\n",
    "# report F-score\n",
    "fScore = (2*(pSum*rSum)/(pSum+rSum))\n",
    "print( f\"F-score: {fScore*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Negative class statistics: \n",
      "Precision: 79.44%\n",
      "Recall: 81.73%\n",
      "Accuracy: 79.50%\n",
      "F-score: 80.57%\n"
     ]
    }
   ],
   "source": [
    "## Report negative class ##\n",
    "print(f\"Negative class statistics: \")\n",
    "\n",
    "# report precision\n",
    "pSum = precision(refsets['neg'], testsets['neg'])\n",
    "print( f\"Precision: {pSum*100:.2f}%\")\n",
    "\n",
    "# report recall\n",
    "rSum = recall(refsets['neg'], testsets['neg'])\n",
    "print( f\"Recall: {rSum*100:.2f}%\")\n",
    "\n",
    "# report accuracy\n",
    "print(f\"Accuracy: {nltk.classify.accuracy(classifier, test_set)*100:.2f}%\")\n",
    "\n",
    "# report F-score\n",
    "fScore = (2*(pSum*rSum)/(pSum+rSum))\n",
    "print( f\"F-score: {fScore*100:.2f}%\")"
   ]
  },
  {
   "source": [
    "<h1>Example statistics: Naive bayes</h1><br>\n",
    "positive class statistics:<br>\n",
    "Precision: 80.85%<br>\n",
    "Recall: 76.00%<br>\n",
    "F-score: 78.35%<br>\n",
    "Model Accuracy: 79.00%<br>\n",
    "<br>\n",
    "Negative class statistics: <br>\n",
    "Precision: 77.36%<br>\n",
    "Recall: 82.00%<br>\n",
    "Model Accuracy: 79.00%<br>\n",
    "F-score: 79.61%<br>\n",
    "<br>\n",
    "<br>\n",
    "<h1>Example statistics: Decision Tree Classifier </h1><br>\n",
    "Positive class statistics: <br>\n",
    "Precision: 50.96%<br>\n",
    "Recall: 53.00%<br>\n",
    "Model Accuracy: 51.00%<br>\n",
    "F-score: 51.96%<br>\n",
    "<br>\n",
    "Negative class statistics:<br>\n",
    "Precision: 51.04%<br>\n",
    "Recall: 49.00%<br>\n",
    "Model Accuracy: 51.00%<br>\n",
    "F-score: 50.00%<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most Informative Features\n               memorable = True              pos : neg    =      9.7 : 1.0\n                 leaving = True              pos : neg    =      8.5 : 1.0\n                   bland = True              neg : pos    =      8.1 : 1.0\n                  normal = True              pos : neg    =      7.9 : 1.0\n               substance = True              neg : pos    =      7.4 : 1.0\n                attempts = True              neg : pos    =      6.2 : 1.0\n                   worse = True              neg : pos    =      6.2 : 1.0\n                   blame = True              neg : pos    =      6.0 : 1.0\n                  jungle = True              neg : pos    =      6.0 : 1.0\n                 routine = True              neg : pos    =      6.0 : 1.0\n                    sick = True              neg : pos    =      6.0 : 1.0\n                 subplot = True              neg : pos    =      6.0 : 1.0\n                  allows = True              pos : neg    =      6.0 : 1.0\n                 married = True              pos : neg    =      6.0 : 1.0\n                   worst = True              neg : pos    =      5.9 : 1.0\n                     key = True              pos : neg    =      5.5 : 1.0\n                     ben = True              pos : neg    =      5.3 : 1.0\n                 closing = True              pos : neg    =      5.3 : 1.0\n                   color = True              pos : neg    =      5.3 : 1.0\n              constantly = True              pos : neg    =      5.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Extra Fun: highest value features in known set\n",
    "classifier.show_most_informative_features(20)"
   ]
  }
 ]
}